{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup as bs\n",
    "\n",
    "from importlib import reload\n",
    "import carfax_scraper \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(carfax_scraper)\n",
    "from carfax_scraper import pull_car_listings, build_car_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size': 14})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "philly = {'url': 'https://www.carfax.com/Used-Cars-in-Philadelphia-PA_c4927',\n",
    "          'zipcode': 19107,\n",
    "          'name': 'philly'}\n",
    "nyc = {'url': 'https://www.carfax.com/Used-Cars-in-Brooklyn-NY_c10456',\n",
    "       'zipcode': 11222, \n",
    "       'name': 'nyc'}\n",
    "\n",
    "location = nyc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# option to work with previously saved results\n",
    "soup_list = []\n",
    "with open(location['name']+'_soup_progress.txt') as f:\n",
    "    html_list = f.read().split('BREAKHERE')\n",
    "html_list.remove('')\n",
    "\n",
    "for page in html_list:\n",
    "    soup = bs(page, parser='lxml')\n",
    "    soup_list.append(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# pull all pages available in search results\n",
    "\n",
    "# soup_list = pull_car_listings(philly, 55)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64 pages collected\n"
     ]
    }
   ],
   "source": [
    "print('%i pages collected'%(len(soup_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape with duplicates: (1600, 14)\n",
      "Shape without duplicates: (1191, 14)\n"
     ]
    }
   ],
   "source": [
    "cars = build_car_df(soup_list).set_index('index')\n",
    "print('Shape with duplicates: (%i, %i)'%(cars.shape[0], cars.shape[1]))\n",
    "\n",
    "cars = cars.drop_duplicates()\n",
    "print('Shape without duplicates: (%i, %i)'%(cars.shape[0], cars.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(df, city=location['name']):\n",
    "    # city: \"philly\" or \"nyc\"\n",
    "\n",
    "    df = format_mileage(df).copy()\n",
    "    \n",
    "    df['location'] = df.apply(get_location, axis=1)\n",
    "\n",
    "    if city=='philly':\n",
    "        df['location'] = df['location'].str.replace('Phila,', 'Philadelphia,').copy()\n",
    "        \n",
    "    df = get_engine_info(df).copy()\n",
    "\n",
    "    df = drop_electric_cars(df).copy()\n",
    "    df = drop_odd_cylinders(df).copy()\n",
    "    df = map_damage_values(df).copy()\n",
    "    df['num_owners'] = df['history'].apply(get_prev_owners).copy()\n",
    "    df['purchase_date'] = pd.to_datetime(df['history'].apply(get_purchase_date)).copy()\n",
    "\n",
    "    # remove redundant column\n",
    "    df.drop(columns='purchase_date', inplace=True)\n",
    "    \n",
    "    unique_options = get_options()\n",
    "    df = format_options(df, unique_options).copy()\n",
    "    \n",
    "    for col in ['price', 'year', 'mileage', 'capacity', 'damage', 'service']:\n",
    "        df.loc[:, col] = pd.to_numeric(df.loc[:, col]).copy()\n",
    "    \n",
    "    df = get_luxury_label(df).copy()\n",
    "    df = get_num_options(df).copy()\n",
    "    df = get_wheel_size(df).copy()\n",
    "    df = get_interior_options(df).copy()\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_mileage(df):\n",
    "    df['mileage'] = df['mileage'].str.replace(',', '').str.replace(' miles', '').copy()\n",
    "    df.loc[df['mileage']==\"N/A\", 'mileage'] = np.nan\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_location(x):\n",
    "    location = x['location']\n",
    "    match = re.search(r'.+(?=\\s\\()', location)\n",
    "    if match:\n",
    "        loc = match.group().split(',')\n",
    "        formatted_location = ','.join([loc[0].title(), loc[1]])\n",
    "        return formatted_location\n",
    "    else:\n",
    "        return(location) \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_engine_info(df):\n",
    "    df['cylinders'] = df['engine'].apply(lambda x: x.split(' ')[0]).copy()\n",
    "    df['cylinders'] = df['cylinders'].str.replace('Electric', '0').astype(int).copy()\n",
    "    df['is_electric'] = df['engine'].apply(lambda x: int(x == 'Electric')).copy()\n",
    "    df['capacity'] = df['engine'].apply(lambda x: x.split(' ')[2] if len(x.split(' ')) > 2 \n",
    "                                            else 0).astype(float).copy()\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_odd_cylinders(cars):\n",
    "    df = cars[cars['cylinders'] % 2 == 0].copy()\n",
    "    \n",
    "    # coding the number of engine cylinders as a categorical variable\n",
    "    df['cylinders'] = df['cylinders'].astype(str).copy()\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_electric_cars(cars):\n",
    "    df = cars[cars['is_electric'] == 0].copy()\n",
    "    df.drop('is_electric', axis=1, inplace=True)\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_damage_values(df):\n",
    "    damage_values = \\\n",
    "            {'No Accident or Damage Reported': 0,\n",
    "\n",
    "             'Accident/No Damage': 1,\n",
    "             'Very Minor Damage': 1,\n",
    "             'Odometer Problem': 1,\n",
    "\n",
    "             'Minor Damage': 2, \n",
    "             'Damage Reported': 2,\n",
    "             'Accident Reported': 2,\n",
    "             'Accident/Minor Damage': 2,\n",
    "             'Vandalism Damage': 2,\n",
    "\n",
    "             'Major Damage': 3}\n",
    "\n",
    "    df['damage'] = df['damage'].map(damage_values).copy()\n",
    "    df['any_damage'] = (df['damage'] > 0).astype(int).copy()\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prev_owners(x):\n",
    "    match = re.search(r'\\d+', x)\n",
    "    if match:\n",
    "        return int(match.group(0))\n",
    "    else:\n",
    "        return (1) # mode of prev owners\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_purchase_date(x):\n",
    "    # extracting original purchase date from owner history \n",
    "    dates = re.search(r'\\d{2}/\\d{2}/\\d{2}', x)\n",
    "    if dates:\n",
    "        return(dates.group(0))\n",
    "    else:\n",
    "        return(np.nan)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_options():\n",
    "    # Returns a list of the unique optional features from the whole dataset\n",
    "    all_options = np.unique(', '.join(cars['options'].unique().astype(str)).split(', '))\n",
    "    unique_options = np.unique([x.lstrip('and ') for x in all_options])[1:]\n",
    "    return unique_options\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_options(df, unique_options):\n",
    "    for option in unique_options:\n",
    "        new_col = option.replace(' ', '_').lower()\n",
    "        df[new_col] = df['options'].str.contains(option).copy()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_luxury_label(df):\n",
    "    response = requests.get('https://www.carfax.com/blog/luxury-car-brands')\n",
    "    soup = bs(response.content)\n",
    "    luxury_brands = [x.text for x in soup.find_all('h3')[1:-3]]\n",
    "\n",
    "    df['luxury'] = df['make'].isin(luxury_brands).astype(int).copy()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_num_options(df):\n",
    "    df['num_options'] = df['options'].apply(lambda x: len(x.split(','))).copy()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wheel_size(df):\n",
    "    df['wheel_size'] = df['options'].apply(lambda x: int(re.search(r'(\\d+\\s)\\bInch Wheels\\b', x).group(1))\n",
    "                                                      if re.search(r'Inch Wheels', x) else None).copy()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_interior_options(df):\n",
    "    \n",
    "    df['leather'] = df['options'].str.contains('Leather').astype(int).copy()\n",
    "    df.drop(columns=df.filter(like='leather_').columns, inplace=True)\n",
    "\n",
    "    df['navigation'] = df['options'].str.contains('Navigation').astype(int).copy()\n",
    "    df.drop(columns=df.filter(like='navigation_').columns, inplace=True)\n",
    "\n",
    "    df['heated_extras'] = df['options'].str.contains('Heated').astype(int).copy()\n",
    "    df.drop(columns=df.filter(regex=r'heated_(?!extras)').columns, inplace=True)\n",
    "\n",
    "    df['driver_support'] = df['options'].str.contains('Driver').astype(int).copy()\n",
    "    df.drop(columns=df.filter(regex=r'driver(?!_support)').columns, inplace=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-19-c792a0a1ab85>:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[new_col] = df['options'].str.contains(option).copy()\n"
     ]
    }
   ],
   "source": [
    "cars = preprocessing(cars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars.filter(like='wd').columns\n",
    "cars.drop(columns=['4wd', 'awd'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combining several highly correlated columns \n",
    "\n",
    "if 'side_airbag' in cars.columns:\n",
    "    cars['side_airbag'] = cars['side_airbag'] | cars['side_airbags']\n",
    "else:\n",
    "    cars['side_airbag'] = cars['side_airbags']\n",
    "cars['spare_tire'] = cars['spare_tire'] | cars['compact_spare_tire']\n",
    "cars['sync'] = cars['sync'] | cars['sync_3']\n",
    "cars['bench_seat'] = cars['bench_seat'] | cars['rear_bench_seat']\n",
    "\n",
    "cars.drop(['side_airbags', 'compact_spare_tire', 'sync_3', 'rear_bench_seat'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change boolean columns to 0 or 1\n",
    "cars[cars.select_dtypes('bool').columns] = cars[cars.select_dtypes('bool').columns].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optionally remove a small number of outliers -- none in current dataset\n",
    "\n",
    "# cars = cars[cars['price']<130000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-29-cde84e1889fb>:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  cars['log_price'] = cars['price'].apply(np.log).copy()\n",
      "<ipython-input-29-cde84e1889fb>:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  cars['log_price_diff'] = (-cars['price_diff']).apply(np.log).copy()\n"
     ]
    }
   ],
   "source": [
    "cars['log_price'] = cars['price'].apply(np.log).copy()\n",
    "cars['log_price_diff'] = (-cars['price_diff']).apply(np.log).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "color          28\n",
       "wheel_size    714\n",
       "dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cars.isna().sum()[cars.isna().sum()>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing values with mode or median values\n",
    "cars['color'] = cars['color'].fillna(cars['color'].mode())\n",
    "cars.loc[cars['color'].isna(), 'color'] = cars['color'].mode()[0]\n",
    "\n",
    "cars['wheel_size'] = cars.groupby(['body_type'])['wheel_size'].apply(lambda x: x.fillna(x.median())).to_list()\n",
    "cars['wheel_size'] = cars['wheel_size'].fillna(cars.wheel_size.median())\n",
    "\n",
    "cars['mileage'] = cars['mileage'].fillna(cars.mileage.mean())\n",
    "\n",
    "# filter out a few positive values in order to analyze (log) price discounts\n",
    "cars = cars[cars['price_diff'] < 0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars.to_csv(location['name']+'_dec2021.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
